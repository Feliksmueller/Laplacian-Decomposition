{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import itertools as it\n",
    "import random as rd\n",
    "import scipy.sparse as sp\n",
    "import scipy.stats as st\n",
    "import math\n",
    "import community as community_louvain\n",
    "import urllib.request\n",
    "import gzip\n",
    "import obonet\n",
    "import colorsys\n",
    "# from colormap import rgb2hex\n",
    "# from colormap import hex2rgb\n",
    "import pickle as pk\n",
    "# from prettytable import PrettyTable\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter, ChainMap\n",
    "import umap\n",
    "import scipy.stats as st\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import scipy.spatial.distance as dist\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import time\n",
    "# import statsmodels.sandbox.stats.multicomp as mc\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import plotly.graph_objects as gp\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eigenlayout(G, dim=3, n_lam=18, n_neighs=10, spread=1.0):\n",
    "    \"\"\"\n",
    "    Compute the UMAP layout of a graph based on its normalized Laplacian matrix.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    G : NetworkX graph object\n",
    "        The input graph.\n",
    "    dim : int, optional (default=3)\n",
    "        The number of dimensions in the UMAP projection.\n",
    "    n_lam : int, optional (default=18)\n",
    "        The number of eigenvalues and eigenvectors to use in the spectral dimensionality reduction.\n",
    "    n_neighs : int, optional (default=10)\n",
    "        The number of nearest neighbors to use in the UMAP algorithm.\n",
    "    spread : float, optional (default=1.0)\n",
    "        The spread of the UMAP projection.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    d_umap_pos : dictionary with graph nodes as keys and aray - shape: (n_nodes, dim) as values\n",
    "        The UMAP projection of the graph nodes as a numpy array.\n",
    "    \"\"\"\n",
    "    if n_lam > G.number_of_nodes()-1:\n",
    "        print('The number of Eigenvectors must be smaller than the number of nodes - 1!')\n",
    "        print('Please provide a smaller number. (Not more than 0.1xnumber_of_nodes recommended)')\n",
    "\n",
    "    # Compute the normalized Laplacian matrix\n",
    "    M_laplace = nx.normalized_laplacian_matrix(G, sorted(G.nodes()))\n",
    "\n",
    "    # Construct the matrix M_ImL = I - L where L is the normalized Laplacian matrix and I is the identity matrix\n",
    "    n_nodes = G.number_of_nodes()\n",
    "    Id = sp.identity(n_nodes)\n",
    "    M_ImL = Id - M_laplace\n",
    "\n",
    "    # Compute the n_lam smallest eigenvalues and eigenvectors of M_ImL\n",
    "    # M_V: #rows = #nodes and #cols = #eigenvls \n",
    "\n",
    "    # take the Markov matrix \n",
    "    Lam,M_V = sp.linalg.eigsh(M_ImL,k=n_lam)\n",
    "\n",
    "    # take the Laplacian matrix \n",
    "    Lam,M_V = sp.linalg.eigsh(M_laplace,k=n_lam)\n",
    "\n",
    "    # FEATURE VECTOR\n",
    "    # re-sort M_V by desc Lam - 1st column: eigenvec for largest Eigenvalue ...\n",
    "    N = n_lam\n",
    "\n",
    "    rev_ordered_idx = np.argsort(Lam)\n",
    "    # spectral dimensional reduction:\n",
    "    f_vec_1 = [x.real for x in M_V[:,rev_ordered_idx[-1]]]\n",
    "    arr = f_vec_1\n",
    "\n",
    "    for m in range(2,N+1):\n",
    "        f_vec_2 = [x.real for x in M_V[:,rev_ordered_idx[-m]]]\n",
    "        arr = np.vstack((arr,f_vec_2))\n",
    "\n",
    "    # # UMAP\n",
    "    FX = arr.transpose()\n",
    "\n",
    "    mind = .2\n",
    "    reducer = umap.UMAP(n_components=dim,n_neighbors=n_neighs, metric = 'cosine', min_dist=mind, spread = spread)\n",
    "    umap_pos = reducer.fit_transform(FX)\n",
    "\n",
    "\n",
    "    d_node_pos = {}\n",
    "\n",
    "    for i, node in enumerate(sorted(G.nodes())):\n",
    "        d_node_pos[node] = umap_pos[i,:]\n",
    "\n",
    "\n",
    "    return d_node_pos, FX\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def download_mapping_file(url, filename):\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "def parse_mapping_file(filename):\n",
    "    mapping = {}\n",
    "    with gzip.open(filename, 'rt') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('#'):  # Skip header and comments\n",
    "                continue\n",
    "            fields = line.strip().split('\\t')\n",
    "            if fields[0] == '9606':\n",
    "                gene_symbol = fields[2]\n",
    "                entrez_id = fields[1]\n",
    "                ensembl_id = fields[5]\n",
    "                # Additional mapping field\n",
    "                gene_name = fields[11]\n",
    "                if gene_symbol not in mapping:\n",
    "                    mapping[gene_symbol] = {\n",
    "                        'entrez_id': entrez_id,\n",
    "                        'ensembl_id': ensembl_id,\n",
    "                        'gene_name': gene_name\n",
    "                    }\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def convert_symbols_to_entrez(gene_symbols, mapping):\n",
    "    entrez_ids = []\n",
    "    for symbol in gene_symbols:\n",
    "        if symbol in mapping:\n",
    "            entrez_ids.append(mapping[symbol]['entrez_id'])\n",
    "    return entrez_ids\n",
    "\n",
    "def convert_symbols_to_ensembl(gene_symbols, mapping):\n",
    "    ensembl_ids = []\n",
    "    for symbol in gene_symbols:\n",
    "        if symbol in mapping:\n",
    "            ensembl_ids.append(mapping[symbol]['ensembl_id'])\n",
    "    return ensembl_ids\n",
    "\n",
    "# # Download Gene Info file (example using Homo sapiens)\n",
    "url = 'ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/GENE_INFO/Mammalia/Homo_sapiens.gene_info.gz'\n",
    "filename = 'Homo_sapiens.gene_info.gz'\n",
    "download_mapping_file(url, filename)\n",
    "\n",
    "# Parse mapping file\n",
    "mapping = parse_mapping_file(filename)\n",
    "\n",
    "# Generate a dictionary of all existing gene symbols and their corresponding Entrez IDs and Ensemble IDs\n",
    "all_gene_symbols = list(mapping.keys())\n",
    "all_entrez_ids = [mapping[symbol]['entrez_id'] for symbol in all_gene_symbols]\n",
    "all_ensembl_ids = [mapping[symbol]['ensembl_id'] for symbol in all_gene_symbols]\n",
    "symbol_to_entrez = dict(zip(all_gene_symbols, all_entrez_ids))\n",
    "symbol_to_ensembl = dict(zip(all_gene_symbols, all_ensembl_ids))\n",
    "entrez_to_symbols = {v: k for k, v in symbol_to_entrez.items()}\n",
    "ensembl_to_symbols = {v: k for k, v in symbol_to_ensembl.items()}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ginfo(G):\n",
    "    info = []\n",
    "    info.append(f\"Graph Name: {G.name}\")\n",
    "    info.append(f\"Graph Type: {type(G).__name__}\")\n",
    "    info.append(f\"Number of Nodes: {G.number_of_nodes()}\")\n",
    "    info.append(f\"Number of Edges: {G.number_of_edges()}\")\n",
    "    info.append(f\"Density: {round(100.*nx.density(G),3)} %\")\n",
    "    info.append(f\"Average Degree: {round(sum(dict(G.degree()).values()) / G.number_of_nodes(),2)}\")\n",
    "    info.append(f\"Connected: {'Yes' if nx.is_connected(G) else 'No'}\")\n",
    "    num_components = nx.number_connected_components(G)\n",
    "    info.append(f\"Number of Connected Components: {num_components}\")\n",
    "   \n",
    "    info.append(f\"Directed: {'Yes' if G.is_directed() else 'No'}\")\n",
    "    return \"\\n\".join(info)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PPI direct\n",
    "path = 'data/'\n",
    "G_ppi = nx.read_edgelist(path + 'PPI_physical_elist.csv',data=False, delimiter=',')\n",
    "print(Ginfo(G_ppi))\n",
    "print('\\n')\n",
    "\n",
    "lcc = max(nx.connected_components(G_ppi), key=len)\n",
    "G = nx.subgraph(G_ppi,lcc)\n",
    "\n",
    "print(Ginfo(G))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spectral decomposition\n",
    "\n",
    "of the symmetric Laplacian \n",
    "(takes like 20 mins)\n",
    "\n",
    "you can make a test run with a smaller sample (see optional next cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 5000  # Number of nodes to sample\n",
    "\n",
    "# Step 1: Randomly sample n nodes from the graph\n",
    "sampled_nodes = rd.sample(list(G.nodes()), n)\n",
    "\n",
    "# Step 2: Create a subgraph with the sampled nodes\n",
    "sampled_subgraph = G.subgraph(sampled_nodes)\n",
    "\n",
    "# Step 3: Extract the largest connected component (LCC)\n",
    "lcc = max(nx.connected_components(sampled_subgraph), key=len)\n",
    "G_lcc_sample = G.subgraph(lcc)\n",
    "\n",
    "print(Ginfo(G_lcc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the normalized Laplacian matrix\n",
    "M_laplace = nx.normalized_laplacian_matrix(G_lcc_sample, sorted(G_lcc_sample.nodes()))\n",
    "\n",
    "n_nodes = G_lcc_sample.number_of_nodes()\n",
    "\n",
    "# Compute the n_lam largest eigenvalues and eigenvectors of M_Laplace\n",
    "Lam, M_V = sp.linalg.eigsh(M_laplace, k=n_nodes-1, which='LM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the eigenvalues as a histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(Lam, bins=30, color='lightblue', edgecolor='black', alpha=0.8)\n",
    "plt.title(\"Histogram of Laplacian Eigenvalues\")\n",
    "plt.xlabel(\"Eigenvalue\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY SPECTRALLY DECOMPOSED EIGENVECTORS FOR LAYOUT\n",
    "\n",
    "d_node_pos, FX = eigenlayout(G_lcc_sample, dim=2, n_lam=30, n_neighs=20, spread=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "x_coords = [d_pos_eigen[node][0] for node in G_lcc_sample.nodes()]\n",
    "y_coords = [d_pos_eigen[node][1] for node in G_lcc_sample.nodes()]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Draw edges first so they appear behind the nodes\n",
    "nx.draw_networkx_edges(G_lcc_sample, pos=d_pos_eigen, edge_color='gray', alpha=0.1,width=.3)\n",
    "\n",
    "plt.scatter(\n",
    "    x_coords, y_coords,\n",
    "    s=10,  # Node size\n",
    "    c='lightblue',  # Inner face color\n",
    "    edgecolors='black',  # Border color\n",
    "    linewidths=1.5,  # Border thickness\n",
    "    alpha=1,  # Node transparency\n",
    "    zorder=3  # Ensure nodes are drawn on top of edges\n",
    ")\n",
    "\n",
    "plt.title(\"Eigenmap\")\n",
    "# plt.xlabel(\"X Coordinate\")\n",
    "# plt.ylabel(\"Y Coordinate\")\n",
    "# plt.axis(\"off\")  # Turn off the axis for a cleaner look\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "\n",
    "\n",
    "# Step 1: Compute the pairwise distance matrix\n",
    "distance_matrix = squareform(pdist(FX, metric='euclidean'))  # Use 'cosine' for cosine similarity\n",
    "\n",
    "# Step 2: Perform hierarchical clustering\n",
    "linkage_matrix = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Step 3: Visualize the dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linkage_matrix)\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.xlabel(\"Node Index\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Extract cluster labels\n",
    "num_clusters = 8  # Specify the desired number of clusters\n",
    "cluster_labels = fcluster(linkage_matrix, num_clusters, criterion='maxclust')\n",
    "\n",
    "# Print cluster labels for each node\n",
    "print(\"Cluster labels:\", cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map each cluster to a unique color\n",
    "# Use a colormap to assign colors to clusters\n",
    "from matplotlib.cm import get_cmap\n",
    "cmap = get_cmap('tab10')  # You can use other colormaps like 'viridis', 'plasma', etc.\n",
    "unique_clusters = np.unique(cluster_labels)\n",
    "cluster_colors = {cluster: cmap(i / len(unique_clusters)) for i, cluster in enumerate(unique_clusters)}\n",
    "\n",
    "# Get x and y coordinates for nodes\n",
    "x_coords = [d_node_pos[node][0] for node in G_lcc_sample.nodes()]\n",
    "y_coords = [d_node_pos[node][1] for node in G_lcc_sample.nodes()]\n",
    "\n",
    "# Assign colors to nodes based on their cluster\n",
    "node_colors = [cluster_colors[cluster_labels[i]] for i, node in enumerate(G_lcc_sample.nodes())]\n",
    "\n",
    "# Plot the network\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Draw edges first so they appear behind the nodes\n",
    "nx.draw_networkx_edges(G_lcc_sample, pos=d_node_pos, edge_color='gray', alpha=0.1, width=0.3)\n",
    "\n",
    "# Draw nodes with cluster-based colors\n",
    "plt.scatter(\n",
    "    x_coords, y_coords,\n",
    "    s=10,  # Node size\n",
    "    c=node_colors,  # Node colors based on clusters\n",
    "    edgecolors='black',  # Border color\n",
    "    linewidths=1.5,  # Border thickness\n",
    "    alpha=1,  # Node transparency\n",
    "    zorder=3  # Ensure nodes are drawn on top of edges\n",
    ")\n",
    "\n",
    "# Add title\n",
    "plt.title(\"Eigenmap with Cluster Coloring\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
